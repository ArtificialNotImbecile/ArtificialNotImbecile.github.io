{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a45a9d35",
   "metadata": {},
   "source": [
    "# convert weight to dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dae170bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch_weight = torch.load(\"../superpoint_v1.pth\", map_location=\"cpu\")\n",
    "tf_dict = {}\n",
    "for k, v in torch_weight.items():\n",
    "    k = k.replace(\".\", '/') + ':0'\n",
    "    if len(v.shape) == 4:\n",
    "        v = v.permute(2, 3, 1, 0)\n",
    "    tf_dict[k] = v.numpy()\n",
    "sorted(tf_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6b226d",
   "metadata": {},
   "source": [
    "# test whether tf result matches torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03f5697f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from superpoint_forward import SuperPointFrontend\n",
    "net = SuperPointFrontend(\"../superpoint_v1.pth\", \"3\", nms_dist=4, conf_thresh=0.015, nn_thresh=0.7)\n",
    "image = cv2.imread(\"../result.jpg\")[:, -200: -100, :]\n",
    "outs_torch = net.run(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e5cf434",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf\n",
    "\n",
    "\n",
    "class SuperPoint(object):\n",
    "    INPUT_NAME = 'input:0'\n",
    "    SEMI_NAME = 'semi:0'\n",
    "    DESC_NAME = 'desc:0'\n",
    "\n",
    "    def __init__(self, frozen_graph, device_id, memory_limit=1024):\n",
    "        gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "        tf.config.experimental.set_visible_devices(gpus[int(device_id)], 'GPU')\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[int(device_id)],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=memory_limit)])\n",
    "        self.graph = tf.Graph()\n",
    "        graph_def = tf.GraphDef()\n",
    "        with tf.gfile.GFile(frozen_graph, 'rb') as fid:\n",
    "            serialized_graph = fid.read()\n",
    "            graph_def.ParseFromString(serialized_graph)\n",
    "\n",
    "        with self.graph.as_default():\n",
    "            tf.import_graph_def(graph_def, name='')\n",
    "\n",
    "        self.sess = tf.Session(graph=self.graph)\n",
    "\n",
    "\n",
    "    def run_single_image(self, image):\n",
    "        img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        img = img.astype(np.float32) / 255\n",
    "        h, w = img.shape[0], img.shape[1]\n",
    "        inp = img.copy().reshape((1, h, w))\n",
    "        inp = np.expand_dims(inp, 0)\n",
    "        outs = self.sess.run([self.SEMI_NAME, self.DESC_NAME], feed_dict={\n",
    "                                     self.INPUT_NAME: inp})\n",
    "        return outs\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74173465",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_model = SuperPoint(\"./superpoint.pb\", \"3\")\n",
    "image = cv2.imread(\"../result.jpg\")[:, -200: -100, :]\n",
    "outs_tf = tf_model.run_single_image(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4cea59a3",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-4.9164e-02, -4.7101e-02, -3.6929e-02,  ..., -7.3134e-03,\n",
       "           -7.6460e-03, -2.2979e-02],\n",
       "          [-6.5429e-02, -9.6710e-02, -8.4849e-02,  ..., -5.3827e-02,\n",
       "           -6.3304e-02, -4.8841e-02],\n",
       "          [-2.3553e-02, -3.5312e-02, -1.9066e-02,  ...,  8.6734e-03,\n",
       "            4.8708e-03,  5.3168e-03],\n",
       "          ...,\n",
       "          [ 2.0157e-02,  7.7801e-03,  3.1948e-02,  ...,  2.1021e-02,\n",
       "            3.6994e-02,  2.5118e-03],\n",
       "          [-1.1968e-02, -6.9366e-02, -4.9406e-02,  ..., -4.8562e-02,\n",
       "           -4.0915e-02, -4.8467e-02],\n",
       "          [ 3.4102e-02,  1.8187e-02,  2.6040e-02,  ...,  6.0794e-02,\n",
       "            3.9990e-02,  1.9080e-02]],\n",
       "\n",
       "         [[-1.2968e-01, -1.2205e-01, -1.2273e-01,  ..., -1.0544e-01,\n",
       "           -1.0159e-01, -6.8733e-02],\n",
       "          [-1.7958e-01, -1.5226e-01, -1.7932e-01,  ..., -1.6897e-01,\n",
       "           -1.5500e-01, -1.2248e-01],\n",
       "          [-1.0561e-01, -7.2009e-02, -9.1663e-02,  ..., -1.2706e-01,\n",
       "           -1.2728e-01, -1.2605e-01],\n",
       "          ...,\n",
       "          [-2.2770e-02, -3.1346e-02, -3.5243e-02,  ...,  1.3035e-02,\n",
       "           -6.7572e-03,  2.7994e-02],\n",
       "          [-8.2591e-02, -6.3559e-02, -9.8952e-02,  ..., -7.3737e-02,\n",
       "           -7.8686e-02, -2.1476e-02],\n",
       "          [-1.0099e-01, -5.1674e-02, -9.2138e-02,  ..., -9.9094e-02,\n",
       "           -8.9402e-02, -2.7353e-02]],\n",
       "\n",
       "         [[-6.8712e-02, -6.8964e-02, -6.5867e-02,  ..., -4.7414e-02,\n",
       "           -5.1723e-02, -5.3337e-02],\n",
       "          [-5.8474e-02, -6.2943e-02, -7.1396e-02,  ..., -5.8061e-02,\n",
       "           -5.4754e-02, -6.2379e-02],\n",
       "          [-9.4237e-02, -9.5333e-02, -9.4935e-02,  ..., -9.5085e-02,\n",
       "           -1.0257e-01, -1.2551e-01],\n",
       "          ...,\n",
       "          [ 9.5089e-02,  1.0916e-01,  1.2767e-01,  ...,  1.3090e-01,\n",
       "            1.2230e-01,  7.2771e-02],\n",
       "          [ 7.1717e-02,  5.2351e-02,  5.4653e-02,  ...,  3.0560e-02,\n",
       "            4.9341e-02,  4.5889e-02],\n",
       "          [ 4.7240e-02,  4.6289e-02,  1.8855e-02,  ...,  2.4011e-02,\n",
       "            2.0552e-02,  3.1798e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 9.0516e-02,  9.3748e-02,  1.1243e-01,  ...,  1.0964e-01,\n",
       "            1.0420e-01,  6.8572e-02],\n",
       "          [ 1.6596e-02, -2.3383e-02, -2.2003e-02,  ..., -4.8195e-02,\n",
       "           -2.8053e-02, -2.9889e-02],\n",
       "          [ 6.2405e-02,  2.3064e-02,  2.8484e-02,  ...,  3.1188e-02,\n",
       "            4.0494e-02,  5.4692e-02],\n",
       "          ...,\n",
       "          [ 9.4902e-02,  1.0977e-01,  1.1066e-01,  ...,  1.2492e-01,\n",
       "            1.3794e-01,  1.3460e-01],\n",
       "          [ 4.9152e-02,  3.5831e-02,  3.4126e-02,  ...,  5.5771e-02,\n",
       "            5.0748e-02,  2.2697e-02],\n",
       "          [-5.2857e-04, -4.3048e-02, -5.5875e-02,  ..., -1.6299e-02,\n",
       "           -2.2369e-03, -1.9314e-02]],\n",
       "\n",
       "         [[-6.5603e-02, -7.7841e-02, -7.3610e-02,  ..., -6.4433e-02,\n",
       "           -3.9754e-02, -6.2143e-02],\n",
       "          [-1.2274e-01, -1.3116e-01, -1.1637e-01,  ..., -1.0723e-01,\n",
       "           -9.2981e-02, -9.5342e-02],\n",
       "          [-3.6115e-02, -2.9734e-02,  9.8638e-03,  ...,  4.4566e-02,\n",
       "            4.5491e-02,  2.2204e-02],\n",
       "          ...,\n",
       "          [-6.9220e-02, -4.6281e-02, -1.7192e-02,  ..., -2.8625e-02,\n",
       "           -2.4051e-02, -2.2775e-04],\n",
       "          [-3.5268e-02, -6.5258e-03,  3.8833e-03,  ..., -2.6167e-02,\n",
       "           -5.9681e-03, -3.9373e-03],\n",
       "          [-8.7071e-03, -3.3598e-03,  2.2941e-02,  ...,  1.3258e-03,\n",
       "            1.8272e-02,  1.7137e-03]],\n",
       "\n",
       "         [[ 4.0073e-02, -6.5600e-07, -1.0539e-02,  ..., -2.8320e-02,\n",
       "           -1.1413e-02, -1.1290e-02],\n",
       "          [ 3.7041e-02, -8.0565e-03, -4.6282e-02,  ..., -6.5762e-02,\n",
       "           -6.1205e-02, -4.8329e-02],\n",
       "          [ 4.9827e-02,  2.8637e-02, -1.5929e-02,  ..., -2.9416e-02,\n",
       "           -5.0209e-02, -6.0886e-02],\n",
       "          ...,\n",
       "          [-1.1661e-02, -1.4581e-05,  3.5719e-03,  ..., -3.2979e-02,\n",
       "           -1.4865e-02,  2.6494e-02],\n",
       "          [-3.3035e-02, -4.0532e-02, -4.5723e-02,  ..., -8.4036e-02,\n",
       "           -4.9108e-02, -5.2101e-02],\n",
       "          [ 1.9384e-02,  3.9605e-02,  3.0999e-02,  ...,  1.4087e-02,\n",
       "            4.6657e-02,  3.6346e-02]]]], device='cuda:3',\n",
       "       grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outs_torch[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0bbc5923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outs_tf[1].shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa24254",
   "metadata": {},
   "source": [
    "# test all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22aa8067",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0670743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0226,  0.0479,  0.0261,  0.0413,  0.0428, -0.0215, -0.0176,  0.0046,\n",
      "        -0.0004, -0.0096], device='cuda:0', grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "from superpoint_forward import SuperPointFrontend\n",
    "import torch\n",
    "net = SuperPointFrontend(\"../superpoint_v1.pth\", \"0\", nms_dist=4, conf_thresh=0.015, nn_thresh=0.7)\n",
    "image = cv2.imread(\"../result.jpg\")[:, -200: -100, :]\n",
    "coarse_desc, samp_pts = net.run(image)\n",
    "coarse_desc = coarse_desc[:, :1, :, :]\n",
    "h, w = image.shape[0], image.shape[1]\n",
    "samp_pts_not_normal = samp_pts.detach().clone()\n",
    "# samp_pts_not_normal = samp_pts_not_normal.transpose(0, 1).contiguous()\n",
    "# samp_pts_not_normal = samp_pts_not_normal.view(1, 1, -1, 2)\n",
    "# torch grid_sample is using normalized grid!!!\n",
    "samp_pts[0, :] = (samp_pts[0, :] / (float(w) / 2.)) - 1.\n",
    "samp_pts[1, :] = (samp_pts[1, :] / (float(h) / 2.)) - 1.\n",
    "samp_pts = samp_pts.transpose(0, 1).contiguous()\n",
    "samp_pts = samp_pts.view(1, 1, -1, 2)\n",
    "samp_pts = samp_pts.float()\n",
    "desc = torch.nn.functional.grid_sample(coarse_desc, samp_pts, align_corners=False)\n",
    "print(desc.squeeze()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c52b9c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "xy = samp_pts_not_normal.cpu().numpy().transpose()\n",
    "yx = np.concatenate([xy[:, 1:], xy[:, :1]], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e31048de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.02591796964406967, 0.05062885209918022, 0.029128430411219597, 0.04363219439983368, 0.046342384070158005, -0.02533014863729477, -0.01879284344613552, 0.006482865661382675, -6.19070342509076e-05, -0.00987747497856617]\n"
     ]
    }
   ],
   "source": [
    "img = coarse_desc.cpu().detach().numpy().transpose([0, 2, 3, 1])[0]\n",
    "img = cv2.resize(img, (w, h)) # to heatmap shape, torch handle this more elegantly! using normalized grid with period\n",
    "img = np.expand_dims(img, (0, -1))\n",
    "img = tf.constant(img)\n",
    "coords = np.expand_dims(yx, (0, 1)).astype(np.float32)\n",
    "coords = tf.constant(coords)\n",
    "out = GridSample([img, coords], 'constant')\n",
    "print(out.numpy().squeeze().transpose().tolist()[:10])\n",
    "\n",
    "# img = coarse_desc.cpu().detach().numpy().transpose([0, 2, 3, 1])\n",
    "# img = tf.constant(img)\n",
    "# coords = np.expand_dims(yx/[h, w]*[73, 12], (0, 1)).astype(np.float32)\n",
    "# coords = tf.constant(coords)\n",
    "# out = GridSample([img, coords])\n",
    "# print(out.numpy().squeeze().transpose()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1352c2c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.5917970e-02,  5.0628852e-02,  2.9128430e-02,  4.3632194e-02,\n",
       "        4.6342384e-02, -2.5330149e-02, -1.8792843e-02,  6.4828657e-03,\n",
       "       -6.1907034e-05, -9.8774750e-03], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "img = coarse_desc.cpu().detach().numpy().transpose([0, 2, 3, 1])[0]\n",
    "src = cv2.resize(img, (100, 590)) # to heatmap shape, torch handle this more elegantly! using normalized grid with period\n",
    "src = src[:, :, None]\n",
    "map_xy = xy[None, :, :].astype(np.float32)\n",
    "desc = cv2.remap(src, map_xy, None, cv2.INTER_LINEAR, borderMode=0)\n",
    "desc[0, :10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b428ece6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.5917970e-02,  5.0628852e-02,  2.9128430e-02,  4.3632194e-02,\n",
       "        4.6342384e-02, -2.5330149e-02, -1.8792843e-02,  6.4828657e-03,\n",
       "       -6.1907034e-05, -9.8774750e-03], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "img = coarse_desc.cpu().detach().numpy().transpose([0, 2, 3, 1])[0]\n",
    "src = cv2.resize(img, (100, 590)) # to heatmap shape, torch handle this more elegantly! using normalized grid with period\n",
    "src = src[:, :, None]\n",
    "map_xy = xy[None, :, :].astype(np.float32)\n",
    "desc = cv2.remap(src, map_xy, None, cv2.INTER_LINEAR, borderMode=0)\n",
    "desc[0, :10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "670850bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def sample(img, coords):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        img: bxhxwxc\n",
    "        coords: bxh2xw2x2. each coordinate is (y, x) integer.\n",
    "            Out of boundary coordinates will be clipped.\n",
    "    Return:\n",
    "        bxh2xw2xc image\n",
    "    \"\"\"\n",
    "    shape = img.get_shape().as_list()[1:]   # h, w, c\n",
    "    batch = tf.shape(img)[0]\n",
    "    shape2 = coords.get_shape().as_list()[1:3]  # h2, w2\n",
    "    assert None not in shape2, coords.get_shape()\n",
    "    max_coor = tf.constant([shape[0] - 1, shape[1] - 1], dtype=tf.float32)\n",
    "\n",
    "    coords = tf.clip_by_value(coords, 0., max_coor)  # borderMode==repeat\n",
    "    coords = tf.cast(coords, tf.int32)\n",
    "\n",
    "    batch_index = tf.range(batch, dtype=tf.int32)\n",
    "    batch_index = tf.reshape(batch_index, [-1, 1, 1, 1])\n",
    "    batch_index = tf.tile(batch_index, [1, shape2[0], shape2[1], 1])    # bxh2xw2x1\n",
    "    indices = tf.concat([batch_index, coords], axis=3)  # bxh2xw2x3\n",
    "    sampled = tf.gather_nd(img, indices)\n",
    "    return sampled\n",
    "\n",
    "\n",
    "def GridSample(inputs, borderMode='repeat'):\n",
    "    \"\"\"\n",
    "    Sample the images using the given coordinates, by bilinear interpolation.\n",
    "    This was described in the paper:\n",
    "    `Spatial Transformer Networks <http://arxiv.org/abs/1506.02025>`_.\n",
    "    This is equivalent to `torch.nn.functional.grid_sample`,\n",
    "    up to some non-trivial coordinate transformation.\n",
    "    This implementation returns pixel value at pixel (1, 1) for a floating point coordinate (1.0, 1.0).\n",
    "    Note that this may not be what you need.\n",
    "    Args:\n",
    "        inputs (list): [images, coords]. images has shape NHWC.\n",
    "            coords has shape (N, H', W', 2), where each pair of the last dimension is a (y, x) real-value\n",
    "            coordinate.\n",
    "        borderMode: either \"repeat\" or \"constant\" (zero-filled)\n",
    "    Returns:\n",
    "        tf.Tensor: a tensor named ``output`` of shape (N, H', W', C).\n",
    "    \"\"\"\n",
    "    image, mapping = inputs\n",
    "    assert image.get_shape().ndims == 4 and mapping.get_shape().ndims == 4\n",
    "    input_shape = image.get_shape().as_list()[1:]\n",
    "    assert None not in input_shape, \\\n",
    "        \"Images in GridSample layer must have fully-defined shape\"\n",
    "    assert borderMode in ['repeat', 'constant']\n",
    "\n",
    "    orig_mapping = mapping\n",
    "    mapping = tf.maximum(mapping, 0.0)\n",
    "    lcoor = tf.floor(mapping)\n",
    "    ucoor = lcoor + 1\n",
    "\n",
    "    diff = mapping - lcoor\n",
    "    neg_diff = 1.0 - diff  # bxh2xw2x2\n",
    "\n",
    "    lcoory, lcoorx = tf.split(lcoor, 2, 3)\n",
    "    ucoory, ucoorx = tf.split(ucoor, 2, 3)\n",
    "\n",
    "    lyux = tf.concat([lcoory, ucoorx], 3)\n",
    "    uylx = tf.concat([ucoory, lcoorx], 3)\n",
    "\n",
    "    diffy, diffx = tf.split(diff, 2, 3)\n",
    "    neg_diffy, neg_diffx = tf.split(neg_diff, 2, 3)\n",
    "\n",
    "    ret = tf.add_n([sample(image, lcoor) * neg_diffx * neg_diffy,\n",
    "                    sample(image, ucoor) * diffx * diffy,\n",
    "                    sample(image, lyux) * neg_diffy * diffx,\n",
    "                    sample(image, uylx) * diffy * neg_diffx], name='sampled')\n",
    "    if borderMode == 'constant':\n",
    "        max_coor = tf.constant([input_shape[0] - 1, input_shape[1] - 1], dtype=tf.float32)\n",
    "        mask = tf.greater_equal(orig_mapping, 0.0)\n",
    "        mask2 = tf.less_equal(orig_mapping, max_coor)\n",
    "        mask = tf.logical_and(mask, mask2)  # bxh2xw2x2\n",
    "        mask = tf.reduce_all(mask, [3])  # bxh2xw2 boolean\n",
    "        mask = tf.expand_dims(mask, 3)\n",
    "        ret = ret * tf.cast(mask, tf.float32)\n",
    "    return tf.identity(ret, name='output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f905bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26ff6b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
